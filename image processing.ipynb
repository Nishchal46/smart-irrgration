{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bad_good.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0BqrVnnRX5ZsWLcpYuCRx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishchal46/smart-irrgration/blob/main/image%20processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6e_lPPNEFGG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28pR039sET_n"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "DATADIR = \"/content/drive/My Drive/project/project\"\n",
        "CATEGORIES = [\"BAD LEAF\",\"GOOD LEAF\"]\n",
        "\n",
        "training_data = []\n",
        "IMG_SIZE = 200\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  \n",
        "\n",
        "        path = os.path.join(DATADIR,category)  \n",
        "        class_num = CATEGORIES.index(category)  \n",
        "\n",
        "        for img in (os.listdir(path)):  \n",
        "            try:\n",
        "              \n",
        "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "                training_data.append([new_array, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "        \n",
        "          \n",
        "\n",
        "create_training_data()\n",
        "\n",
        "print(len(training_data))\n",
        "   \n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZBUme5gEeSu"
      },
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "#print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y= np.array(y)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NImc0BgrEknP"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "\n",
        "X = X/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "\n",
        "model.add(Dense(64))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ove9lAEHEuxo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "524750c4-74a9-48c5-bbb1-71e94a47d7a5"
      },
      "source": [
        "model.fit(X, y, batch_size=2, epochs=5, validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "86/86 [==============================] - 147s 2s/step - loss: 2.0553 - accuracy: 0.5439 - val_loss: 0.7988 - val_accuracy: 0.6622\n",
            "Epoch 2/5\n",
            "86/86 [==============================] - 147s 2s/step - loss: 0.4610 - accuracy: 0.8304 - val_loss: 2.4394 - val_accuracy: 0.6892\n",
            "Epoch 3/5\n",
            "86/86 [==============================] - 147s 2s/step - loss: 0.2138 - accuracy: 0.8947 - val_loss: 2.8986 - val_accuracy: 0.7297\n",
            "Epoch 4/5\n",
            "86/86 [==============================] - 147s 2s/step - loss: 0.2033 - accuracy: 0.9532 - val_loss: 2.6883 - val_accuracy: 0.7297\n",
            "Epoch 5/5\n",
            "86/86 [==============================] - 147s 2s/step - loss: 0.2147 - accuracy: 0.9474 - val_loss: 9.3745 - val_accuracy: 0.6081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0316492080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sdnp6tpPBQ8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG87VYRRIJu1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkw9TItTE0A1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "94219a45-cc4e-43dc-dce6-f33a0907d071"
      },
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "CATEGORIES = [\"BAD LEAF\", \"GOOD LEAF\"]\n",
        "\n",
        "#DATADIR = \"/content/drive/My Drive/project/GOOD LEAF\"\n",
        "\n",
        "\n",
        "def prepare(file):\n",
        "    IMG_SIZE = 200  # 50 in txt-based\n",
        "    filepath = os.path.join(DATADIR,file) \n",
        "    img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "\n",
        "#model = tf.keras.models.load_model(\"good_bad_leaf.model\")\n",
        "\n",
        "prediction = model.predict([prepare(\"/content/drive/My Drive/31.jpg\")])\n",
        "print(prediction)  # will be a list in a list.\n",
        "print(CATEGORIES[int(prediction[0][0])])\n",
        "\n",
        "#for file in os.listdir(DATADIR):\n",
        " # prediction = model.predict([prepare(file)])\n",
        "  #print(prediction)  # will be a list in a list.\n",
        "  #print(CATEGORIES[int(prediction[0][0])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]]\n",
            "GOOD LEAF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXoxG9iVE9b9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}